import {
  Injectable,
  NestMiddleware,
  HttpException,
  HttpStatus,
  Logger,
} from '@nestjs/common';
import { Request, Response, NextFunction } from 'express';
import { CacheService } from '../cache/cache.service';
import {
  RateLimitConfig,
  getRateLimitConfig,
  findRateLimitRule,
} from '../config/rate-limit.config';

@Injectable()
export class RateLimitMiddleware implements NestMiddleware {
  private readonly logger = new Logger(RateLimitMiddleware.name);

  constructor(private readonly cacheService: CacheService) {}

  use(req: Request, res: Response, next: NextFunction) {
    this.logger.log(
      `ğŸš€ Rate limit middleware triggered for: ${req.method} ${req.url} from ${req.ip || req.connection.remoteAddress || 'unknown'}`,
    );

    // Get rate limit configuration using the config pattern
    const rule = findRateLimitRule(req);
    const config = getRateLimitConfig(req);

    if (rule) {
      this.logger.log(
        `ğŸ¯ Matched rate limit rule: "${rule.name}" - ${config.description || rule.name}`,
      );
    } else {
      this.logger.log(`ğŸ¯ Using default rate limit configuration`);
    }

    this.logger.log(
      `âš™ï¸ Rate limit config: ${config.maxRequests} requests per ${config.windowMs / 1000 / 60} minutes`,
    );

    void this.handleRateLimit(req, res, next, config);
  }

  private async handleRateLimit(
    req: Request,
    res: Response,
    next: NextFunction,
    config: RateLimitConfig,
  ) {
    const route = `${req.method} ${req.url}`;
    const clientIP = req.ip || req.connection.remoteAddress || 'unknown';

    this.logger.log(
      `ğŸ” Starting rate limit check for: ${route} from ${clientIP}`,
    );
    this.logger.log(
      `âš™ï¸ Rate limit config: ${config.maxRequests} requests per ${config.windowMs / 1000 / 60} minutes`,
    );

    try {
      const key = this.generateKey(req, config);
      this.logger.log(`ğŸ”‘ Generated rate limit key: ${key}`);

      const current = await this.getCurrentRequests(key);
      this.logger.log(
        `ğŸ“Š Current requests for ${key}: ${current}/${config.maxRequests} (${Math.round((current / config.maxRequests) * 100)}% used)`,
      );

      if (current >= config.maxRequests) {
        const retryAfter = await this.getRetryAfter(key, config.windowMs);

        this.logger.warn(`ğŸš« RATE LIMIT EXCEEDED! Key: ${key}`);
        this.logger.warn(`ğŸš« Route: ${route} from ${clientIP}`);
        this.logger.warn(
          `ğŸš« Current: ${current}/${config.maxRequests} (100% used)`,
        );
        this.logger.warn(
          `ğŸš« Retry after: ${retryAfter} seconds (${new Date(Date.now() + retryAfter * 1000).toISOString()})`,
        );

        res.setHeader('X-RateLimit-Limit', config.maxRequests);
        res.setHeader('X-RateLimit-Remaining', 0);
        res.setHeader('X-RateLimit-Reset', Date.now() + retryAfter * 1000);
        res.setHeader('Retry-After', retryAfter);

        // Return 429 response without throwing exception to prevent crashes
        res.status(HttpStatus.TOO_MANY_REQUESTS).json({
          message: 'Too many requests',
          retryAfter: retryAfter,
        });
        return; // Stop processing, don't call next()
      }

      // Increment request count
      this.logger.log(`ğŸ“ˆ Incrementing request count for key: ${key}`);
      await this.incrementRequests(key, current, config.windowMs);

      // Set rate limit headers
      const remaining = Math.max(0, config.maxRequests - current - 1);
      const resetTime = Date.now() + config.windowMs;

      res.setHeader('X-RateLimit-Limit', config.maxRequests);
      res.setHeader('X-RateLimit-Remaining', remaining);
      res.setHeader('X-RateLimit-Reset', resetTime);

      this.logger.log(`âœ… Rate limit check PASSED for key: ${key}`);
      this.logger.log(`âœ… Route: ${route} from ${clientIP}`);
      this.logger.log(
        `âœ… New count: ${current + 1}/${config.maxRequests} (${Math.round(((current + 1) / config.maxRequests) * 100)}% used)`,
      );
      this.logger.log(`âœ… Remaining: ${remaining} requests`);
      this.logger.log(`âœ… Reset time: ${new Date(resetTime).toISOString()}`);

      next();
    } catch (error) {
      this.logger.error(
        `âŒ Rate limit error for key: ${this.generateKey(req, config)} (${route} from ${clientIP})`,
      );
      this.logger.error(`âŒ Error details:`, error.stack);
      // If Redis is unavailable, allow the request to proceed
      this.logger.warn(
        `âš ï¸ Redis unavailable, allowing request to proceed: ${route} from ${clientIP}`,
      );
      this.logger.warn(
        `âš ï¸ This bypasses rate limiting - Redis should be checked!`,
      );
      next();
    }
  }

  private generateKey(req: Request, config: RateLimitConfig): string {
    if (config.keyGenerator) {
      const customKey = config.keyGenerator(req);
      this.logger.log(`ğŸ”§ Using custom key generator: ${customKey}`);
      return customKey;
    }

    // Default key generation based on IP and route
    const ip = req.ip || req.connection.remoteAddress || 'unknown';
    const route = req.route?.path || req.path;
    const defaultKey = `rate_limit:${ip}:${route}`;
    this.logger.log(`ğŸ”§ Using default key generator: ${defaultKey}`);
    return defaultKey;
  }

  private async getCurrentRequests(key: string): Promise<number> {
    try {
      this.logger.log(
        `ğŸ” Fetching current request count from Redis for key: ${key}`,
      );
      const data = await this.cacheService.getCache(key);

      if (!data) {
        this.logger.log(`ğŸ“Š No data found for ${key}, returning 0`);
        return 0;
      }

      const parsed = JSON.parse(data as string);
      const count = parsed.count || 0;
      this.logger.log(`ğŸ“Š Redis returned count for ${key}: ${count}`);
      return count;
    } catch (error) {
      this.logger.error(`âŒ Error getting current requests for key: ${key}`);
      this.logger.error(`âŒ Redis error details:`, error.stack);
      return 0;
    }
  }

  private async incrementRequests(
    key: string,
    currentCount: number,
    windowMs: number,
  ): Promise<void> {
    try {
      this.logger.log(`ğŸ“ˆ Starting increment for key: ${key}`);
      const newCount = currentCount + 1;
      const ttlSeconds = windowMs / 1000;

      // Store both count and window start time
      const windowStart = Date.now();
      const data = JSON.stringify({
        count: newCount,
        windowStart: windowStart,
      });

      this.logger.log(
        `ğŸ“ˆ Setting Redis cache: key=${key}, value=${data}, ttl=${ttlSeconds}s`,
      );
      await this.cacheService.setCache(key, data, ttlSeconds);
      this.logger.log(
        `âœ… Successfully incremented requests for key: ${key} to ${newCount} (TTL: ${ttlSeconds}s)`,
      );
    } catch (error) {
      this.logger.error(`âŒ Error incrementing requests for key: ${key}`);
      this.logger.error(`âŒ Redis increment error details:`, error.stack);
      // If Redis fails, continue without rate limiting
    }
  }

  private async getRetryAfter(key: string, windowMs: number): Promise<number> {
    try {
      // Get the stored data to find window start time
      const data = await this.cacheService.getCache(key);

      if (!data) {
        // No data found, use window time as fallback
        const fallbackSeconds = Math.ceil(windowMs / 1000);
        this.logger.log(
          `â° No data found for ${key}, using fallback: ${fallbackSeconds} seconds`,
        );
        return fallbackSeconds;
      }

      const parsed = JSON.parse(data as string);
      const windowStart = parsed.windowStart;

      if (!windowStart) {
        // No window start time, use fallback
        const fallbackSeconds = Math.ceil(windowMs / 1000);
        this.logger.log(
          `â° No window start time for ${key}, using fallback: ${fallbackSeconds} seconds`,
        );
        return fallbackSeconds;
      }

      // Calculate time remaining in the window
      const now = Date.now();
      const windowEnd = windowStart + windowMs;
      const timeRemaining = Math.max(0, windowEnd - now);
      const secondsRemaining = Math.ceil(timeRemaining / 1000);

      this.logger.log(
        `â° Window start: ${new Date(windowStart).toISOString()}`,
      );
      this.logger.log(`â° Window end: ${new Date(windowEnd).toISOString()}`);
      this.logger.log(`â° Time remaining: ${secondsRemaining} seconds`);

      return secondsRemaining;
    } catch (error) {
      this.logger.error(
        `âŒ Error getting retry time for key: ${key}`,
        error.stack,
      );
      // Fallback: use the window time
      return Math.ceil(windowMs / 1000);
    }
  }

  // Static method for creating rate limit middleware with custom config
  static create(config: Partial<RateLimitConfig> = {}) {
    return (req: Request, res: Response, next: NextFunction) => {
      const middleware = new RateLimitMiddleware(null as any); // We'll inject RedisService properly
      const baseConfig = getRateLimitConfig(req);
      const mergedConfig = { ...baseConfig, ...config };
      middleware.logger.log(
        `ğŸ”§ Creating custom rate limit middleware with config:`,
        mergedConfig,
      );
      void middleware.handleRateLimit(req, res, next, mergedConfig);
    };
  }
}
